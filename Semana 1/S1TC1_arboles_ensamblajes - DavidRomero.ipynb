{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de árboles de decisión y métodos de ensamblaje\n",
    "\n",
    "En este taller podrá poner en práctica los sus conocimientos sobre construcción e implementación de árboles de decisión y métodos de ensamblajes. El taller está constituido por 9 puntos, 5 relacionados con árboles de decisión (parte A) y 4 con métodos de ensamblaje (parte B)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte A - Árboles de decisión\n",
    "\n",
    "En esta parte del taller se usará el conjunto de datos de Capital Bikeshare de Kaggle, donde cada observación representa el alquiler de una bicicleta durante una hora y día determinado. Para más detalles puede visitar los siguientes enlaces: [datos](https://github.com/justmarkham/DAT8/blob/master/data/bikeshare.csv), [dicccionario de datos](https://www.kaggle.com/c/bike-sharing-demand/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos prestamo de bicicletas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "\n",
    "# Libreiras adicionales\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>total</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     season  holiday  workingday  weather  temp   atemp  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "                     humidity  windspeed  casual  registered  total  hour  \n",
       "datetime                                                                   \n",
       "2011-01-01 00:00:00        81        0.0       3          13     16     0  \n",
       "2011-01-01 01:00:00        80        0.0       8          32     40     1  \n",
       "2011-01-01 02:00:00        80        0.0       5          27     32     2  \n",
       "2011-01-01 03:00:00        75        0.0       3          10     13     3  \n",
       "2011-01-01 04:00:00        75        0.0       0           1      1     4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "bikes = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/bikeshare.csv', index_col='datetime', parse_dates=True)\n",
    "# Renombrar variable \"count\" a \"total\"\n",
    "bikes.rename(columns={'count':'total'}, inplace=True)\n",
    "# Crear la hora como una variable \n",
    "bikes['hour'] = bikes.index.hour\n",
    "# Visualización\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Análisis descriptivo\n",
    "\n",
    "Ejecute las celdas 1.1 y 1.2. A partir de los resultados realice un análisis descriptivo sobre las variables hour y workingday, escriba sus inferencias sobre los datos. Para complementar su análisis puede usar métricas como máximo, mínimo, percentiles entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workingday\n",
       "0    188.506621\n",
       "1    193.011873\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 1.1\n",
    "bikes.groupby('workingday').total.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "0      55.138462\n",
       "1      33.859031\n",
       "2      22.899554\n",
       "3      11.757506\n",
       "4       6.407240\n",
       "5      19.767699\n",
       "6      76.259341\n",
       "7     213.116484\n",
       "8     362.769231\n",
       "9     221.780220\n",
       "10    175.092308\n",
       "11    210.674725\n",
       "12    256.508772\n",
       "13    257.787281\n",
       "14    243.442982\n",
       "15    254.298246\n",
       "16    316.372807\n",
       "17    468.765351\n",
       "18    430.859649\n",
       "19    315.278509\n",
       "20    228.517544\n",
       "21    173.370614\n",
       "22    133.576754\n",
       "23     89.508772\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 1.2\n",
    "bikes.groupby('hour').total.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución\n",
    "\n",
    "A continuación se calculan otras métricas adicionales para las variablea a analizar, entre las que se encuentran la desviación estándar, valores máximos y mínimos, así como los cuartiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workingday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3474.0</td>\n",
       "      <td>188.506621</td>\n",
       "      <td>173.724015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7412.0</td>\n",
       "      <td>193.011873</td>\n",
       "      <td>184.513659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>977.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean         std  min   25%    50%    75%    max\n",
       "workingday                                                                \n",
       "0           3474.0  188.506621  173.724015  1.0  44.0  128.0  304.0  783.0\n",
       "1           7412.0  193.011873  184.513659  1.0  41.0  151.0  277.0  977.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.groupby('workingday').total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>455.0</td>\n",
       "      <td>55.138462</td>\n",
       "      <td>43.620012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>74.50</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>454.0</td>\n",
       "      <td>33.859031</td>\n",
       "      <td>34.112105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>46.00</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448.0</td>\n",
       "      <td>22.899554</td>\n",
       "      <td>26.110267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>433.0</td>\n",
       "      <td>11.757506</td>\n",
       "      <td>12.666442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>442.0</td>\n",
       "      <td>6.407240</td>\n",
       "      <td>4.217633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>452.0</td>\n",
       "      <td>19.767699</td>\n",
       "      <td>12.784293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>455.0</td>\n",
       "      <td>76.259341</td>\n",
       "      <td>54.745333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>75.0</td>\n",
       "      <td>118.00</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>455.0</td>\n",
       "      <td>213.116484</td>\n",
       "      <td>159.207044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>208.0</td>\n",
       "      <td>334.00</td>\n",
       "      <td>596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>455.0</td>\n",
       "      <td>362.769231</td>\n",
       "      <td>231.723065</td>\n",
       "      <td>8.0</td>\n",
       "      <td>133.50</td>\n",
       "      <td>392.0</td>\n",
       "      <td>563.50</td>\n",
       "      <td>839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>455.0</td>\n",
       "      <td>221.780220</td>\n",
       "      <td>92.099209</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.00</td>\n",
       "      <td>217.0</td>\n",
       "      <td>294.50</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>455.0</td>\n",
       "      <td>175.092308</td>\n",
       "      <td>101.807629</td>\n",
       "      <td>17.0</td>\n",
       "      <td>106.00</td>\n",
       "      <td>149.0</td>\n",
       "      <td>218.50</td>\n",
       "      <td>539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>455.0</td>\n",
       "      <td>210.674725</td>\n",
       "      <td>127.444294</td>\n",
       "      <td>10.0</td>\n",
       "      <td>123.00</td>\n",
       "      <td>183.0</td>\n",
       "      <td>265.50</td>\n",
       "      <td>647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>456.0</td>\n",
       "      <td>256.508772</td>\n",
       "      <td>143.881880</td>\n",
       "      <td>3.0</td>\n",
       "      <td>157.00</td>\n",
       "      <td>234.5</td>\n",
       "      <td>332.00</td>\n",
       "      <td>757.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>456.0</td>\n",
       "      <td>257.787281</td>\n",
       "      <td>149.167185</td>\n",
       "      <td>11.0</td>\n",
       "      <td>154.00</td>\n",
       "      <td>226.5</td>\n",
       "      <td>329.00</td>\n",
       "      <td>729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>456.0</td>\n",
       "      <td>243.442982</td>\n",
       "      <td>147.563199</td>\n",
       "      <td>12.0</td>\n",
       "      <td>144.00</td>\n",
       "      <td>212.0</td>\n",
       "      <td>311.25</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>456.0</td>\n",
       "      <td>254.298246</td>\n",
       "      <td>144.235670</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.00</td>\n",
       "      <td>232.0</td>\n",
       "      <td>331.00</td>\n",
       "      <td>724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>456.0</td>\n",
       "      <td>316.372807</td>\n",
       "      <td>145.664786</td>\n",
       "      <td>11.0</td>\n",
       "      <td>211.75</td>\n",
       "      <td>309.5</td>\n",
       "      <td>421.00</td>\n",
       "      <td>783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>456.0</td>\n",
       "      <td>468.765351</td>\n",
       "      <td>223.775485</td>\n",
       "      <td>15.0</td>\n",
       "      <td>277.00</td>\n",
       "      <td>480.5</td>\n",
       "      <td>608.50</td>\n",
       "      <td>970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456.0</td>\n",
       "      <td>430.859649</td>\n",
       "      <td>219.908138</td>\n",
       "      <td>23.0</td>\n",
       "      <td>240.75</td>\n",
       "      <td>422.5</td>\n",
       "      <td>564.00</td>\n",
       "      <td>977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>456.0</td>\n",
       "      <td>315.278509</td>\n",
       "      <td>156.641732</td>\n",
       "      <td>11.0</td>\n",
       "      <td>190.00</td>\n",
       "      <td>312.5</td>\n",
       "      <td>416.00</td>\n",
       "      <td>743.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>456.0</td>\n",
       "      <td>228.517544</td>\n",
       "      <td>116.411565</td>\n",
       "      <td>11.0</td>\n",
       "      <td>136.75</td>\n",
       "      <td>224.0</td>\n",
       "      <td>302.00</td>\n",
       "      <td>551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>456.0</td>\n",
       "      <td>173.370614</td>\n",
       "      <td>87.629319</td>\n",
       "      <td>6.0</td>\n",
       "      <td>103.50</td>\n",
       "      <td>171.5</td>\n",
       "      <td>230.00</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>456.0</td>\n",
       "      <td>133.576754</td>\n",
       "      <td>69.844495</td>\n",
       "      <td>9.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>129.0</td>\n",
       "      <td>175.00</td>\n",
       "      <td>502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>456.0</td>\n",
       "      <td>89.508772</td>\n",
       "      <td>51.638004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.75</td>\n",
       "      <td>80.0</td>\n",
       "      <td>123.00</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count        mean         std   min     25%    50%     75%    max\n",
       "hour                                                                   \n",
       "0     455.0   55.138462   43.620012   2.0   24.00   41.0   74.50  283.0\n",
       "1     454.0   33.859031   34.112105   1.0   11.00   19.0   46.00  168.0\n",
       "2     448.0   22.899554   26.110267   1.0    5.00   11.0   32.00  119.0\n",
       "3     433.0   11.757506   12.666442   1.0    3.00    6.0   15.00   66.0\n",
       "4     442.0    6.407240    4.217633   1.0    3.00    6.0    9.00   28.0\n",
       "5     452.0   19.767699   12.784293   1.0    8.00   19.0   29.00   57.0\n",
       "6     455.0   76.259341   54.745333   1.0   24.50   75.0  118.00  213.0\n",
       "7     455.0  213.116484  159.207044   1.0   63.00  208.0  334.00  596.0\n",
       "8     455.0  362.769231  231.723065   8.0  133.50  392.0  563.50  839.0\n",
       "9     455.0  221.780220   92.099209  14.0  161.00  217.0  294.50  414.0\n",
       "10    455.0  175.092308  101.807629  17.0  106.00  149.0  218.50  539.0\n",
       "11    455.0  210.674725  127.444294  10.0  123.00  183.0  265.50  647.0\n",
       "12    456.0  256.508772  143.881880   3.0  157.00  234.5  332.00  757.0\n",
       "13    456.0  257.787281  149.167185  11.0  154.00  226.5  329.00  729.0\n",
       "14    456.0  243.442982  147.563199  12.0  144.00  212.0  311.25  730.0\n",
       "15    456.0  254.298246  144.235670   7.0  154.00  232.0  331.00  724.0\n",
       "16    456.0  316.372807  145.664786  11.0  211.75  309.5  421.00  783.0\n",
       "17    456.0  468.765351  223.775485  15.0  277.00  480.5  608.50  970.0\n",
       "18    456.0  430.859649  219.908138  23.0  240.75  422.5  564.00  977.0\n",
       "19    456.0  315.278509  156.641732  11.0  190.00  312.5  416.00  743.0\n",
       "20    456.0  228.517544  116.411565  11.0  136.75  224.0  302.00  551.0\n",
       "21    456.0  173.370614   87.629319   6.0  103.50  171.5  230.00  584.0\n",
       "22    456.0  133.576754   69.844495   9.0   80.00  129.0  175.00  502.0\n",
       "23    456.0   89.508772   51.638004   4.0   52.75   80.0  123.00  256.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.groupby('hour').total.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variable `hour`\n",
    "\n",
    "Esta variable hace referencia a la hora del día en que se realizó un alquiler de bicicleta.<br>\n",
    "Es posible ver de la ejecución de las celdas anteriores que la mayor concentración del total de alquileres se encuentra en la franja de las 16:00 a las 19:00, donde se alcanzan hasta 977 solicitudes de alquiler en punto de la demanda. Por su parte, el intervalo comprendido entre las 3:00 y las 5:00 se constituye como el periodo de tiempo en el que hay una menor cantidad de alquileres de bicicletas. \n",
    "\n",
    "* Variable `workingday`\n",
    "\n",
    "Del diccionario de datos se pudo establecer que este 'feature' hace referencia a un indicativo binario que toma valor de 0 cuando la fecha de la observación registrada corresponde a un festivo o fin de semana, y asumirá valor de 1 de lo contrario. Resultado de las métricas anteriores es posible concluir que hay mayor cantidad de observaciones (7412 de 10886) que fueron registradas en días habituales que aquellas en festivos o fines de semana; sin embargo el promedio de alquileres en los días feriados es ligeramente inferior al del resto de la semana. Esto podría indicar que las personas alquilarán menos bicicletas en los fines de semana y feriados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Análisis de gráficos\n",
    "\n",
    "Primero ejecute la celda 2.1 y asegúrese de comprender el código y el resultado. Luego, en cada una de celdas 2.2 y 2.3 escriba un código que genere una gráfica de las rentas promedio por hora cuando la variable \"workingday\" es igual a 0 e igual a 1, respectivamente. Analice y escriba sus hallazgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='hour'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.1 - rentas promedio para cada valor de la variable \"hour\"\n",
    "bikes.groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución\n",
    "\n",
    "A continuación se muestran las gráficas solicitadas en el enunciado y su análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='hour'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEHCAYAAABV4gY/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtkklEQVR4nO3deXiV9Zn/8fedPSEkISSEbBCWABKBAAFB3FBBxCpoXbBqcalOlU612ml1Zn6/aWfG3zjTWqsdca1CXVisG9ZdQNSqhLBvAQKBrCSBkAUCWe/fHznUFAIJJCfPWe7XdeU65zzneXLunOvkkyff57uIqmKMMca3BDhdgDHGmO5n4W6MMT7Iwt0YY3yQhbsxxvggC3djjPFBFu7GGOODgjq7o4gEAjlAsap+T0RigSVAGrAXuFFVD7n2fQS4C2gGfqqqH5/ue8fFxWlaWtrZ1G+MMX5r7dq1B1Q1vr3nOh3uwP3AdiDK9fhhYLmqPiYiD7se/1JERgJzgAwgCfhMRIapavOpvnFaWho5OTlnUIoxxhgR2Xeq5zrVLCMiKcBVwIttNs8CFrruLwRmt9m+WFXrVTUfyAMmnmHNxhhjuqCzbe6/B34BtLTZlqCqpQCu236u7clAYZv9ilzbjDHG9JAOw11EvgeUq+raTn5PaWfbSXMciMg9IpIjIjkVFRWd/NbGGGM6ozNn7lOAa0RkL7AYuFREXgXKRCQRwHVb7tq/CEhtc3wKUHLiN1XV51U1S1Wz4uPbvR5gjDHmLHUY7qr6iKqmqGoarRdKV6jqrcAyYK5rt7nAu677y4A5IhIqIoOAdCC72ys3xhhzSmfSW+ZEjwFLReQuoAC4AUBVt4rIUmAb0ATMO11PGWOMMd1PPGHK36ysLLWukMYYc2ZEZK2qZrX3nI1QNaYHqCrbSmp48cs9rN13CE84qTK+rSvNMsaYDuSVH+Yvm0p4b2MJuyuO/G37gNgIZmcmMWtsMkPiIx2s0PgqC3djullhZR3vbSrhvY2lbC+tQQTOGxTLHVMGcfGweFbnV/LO+mL+d2UeT63IY0xKNLMyk7l6TBLxvUOdLt/4CGtzN6Yb7K8+xvubS3lvYwkbCqsAGDsghqtHJ3HV6EQSosJOOqas5hjvbSzh7fXFbC2pITBAuGBoHLPHJjF9ZH96hdq5lzm907W5W7gbc5YOHq7ngy37eW9jCWv2VqIKGUlRXD0miatGJZIaG9Hp77WrrJZ3NhTzzvoSiquOEh4cyBUZCcwam8yFQ+MICrTLY+ZkFu7GdLNPt5Xx41fX0tyiDO0XydWjk/jemMQut5+3tChrCw7x9vpi3t9USvXRRuIiQzh/SByjkqPJSI7i3ORoosKCu+knMd7Mwt2YbtTSosx48guaW5SnbxnH8ITeiLQ360bX1Dc1s2pHBcs2lrC+oIriqqN/ey6tbwQZydGMcn1lJEURExHS7TUYz3a6cLdGPWPO0PLccnaWHeaJm8Ywon9UxwecpdCgQKZn9Gd6Rn+gtRloS0kNW4qr2VJczcbCKt7fVPq3/VNjw11B3xr4o1OiLfD9mIW7MWdAVZn/eR4pfcK5enRSj75238hQLh4Wz8XDvpuL6dCRBraUVLOluDX0NxdX88Hm/X97fnhCbyYM6sOEtFgmDoolMTq8R2s2zrFwN+YMfLunkvUFVfzHrAyPuMjZp1cIF6bHc2H6d4FfXdfIlpJq1u07RPbeSt5eV8yr3xYAkNInnIlpsUwYFMuEtFiGxPdyS5OScZ6FuzFnYP7necRFhnBDVmrHOzskOiKYKUPjmDI0DoCm5ha2l9aSvbeSNfmVrNpZwVvriwHo2yuErLTvzuxHJkZ5xB8t03UW7sZ00uaiar7cdYBfzBhOWHCg0+V0WlBgAKNSohmVEs1dFwxCVdlz4Ahr8itbA39vJR9vLQMgMTqMRXdPIi2ul8NVm66ycDemk55ZlUfv0CBunTTQ6VK6REQYEh/JkPhI5kwcAEBp9VGy8yv51bKtzH05mzfvPZ+4SBst683s/y9jOmF3xWE+3LKf2yYP9Mk+5onR4czKTObFuRPYX32Muxasoa6hyemyTBdYuBvTCc+t2k1IYAB3XjDI6VLcavzAPvzh5rFsLq5m3mvraGpu6fgg45Es3I3pQGn1Ud5eX8xNE1L9oqliekZ//mP2uazcUcG/vL3Fpif2UtbmbkwHXvginxaFuy8c7HQpPeaW8wayv/oYf1iRR//oMH42bZjTJZkz1OGZu4iEiUi2iGwUka0i8mvX9l+JSLGIbHB9zWxzzCMikiciO0TkCnf+AMa4U+WRBhZlFzBrTNIZTQTmCx6cNozrx6fw5PJdLMoucLocc4Y6c+ZeD1yqqodFJBj4SkQ+dD33hKr+tu3OIjKS1oW0M4Ak4DMRGWbrqBpvtODrvRxtbObHlwxxupQeJyL813WjqKit51/f2UK/3qFcdk6C02WZTurwzF1bHXY9DHZ9na4RbhawWFXrVTUfyAMmdrlSY3rY4fomFn69l2kjExiW0NvpchwRHBjA/FvGMTIxinmvr2N9wSGnSzKd1KkLqiISKCIbgHLgU1Vd7XrqJyKySUReEpE+rm3JQGGbw4tc24zxKotWF1B9tJH7/PCsva1eoUG8dPsE+vUO466FOeQfONLxQcZxnQp3VW1W1UwgBZgoIucCzwBDgEygFHjctXt7E1WcdKYvIveISI6I5FRUVJxF6ca4T31TMy9+tYfJg/sydkCfjg/wcfG9Q1l4Z+s/4HNfyqaitt7hikxHzqgrpKpWAZ8DM1S1zBX6LcALfNf0UgS0nXgjBShp53s9r6pZqpoVHx9/4tPGOOrtdcWU1dRz31T/Pmtva1BcL166fQIVtfXcuWANR+ptkJMn60xvmXgRiXHdDwcuB3JFJLHNbtcCW1z3lwFzRCRURAYB6UB2t1ZtjBs1tyjPfbGHUcnRXOCafMu0ykyN4X9/MJatJdXc99o6Gm2Qk8fqzJl7IrBSRDYBa2htc/8L8D8istm1fSrwMwBV3QosBbYBHwHzrKeM8SYfbikl/8AR7rtkiE2H247Lzkng0WtHsWpnBf/81mYb5OShOuwKqaqbgLHtbL/tNMc8CjzatdKM6XmqyvyVuxkc34srXCsgmZPdPHEA+6uP8eTyXSRGh/Hg9OFOl2ROYNMPGNPGqp0VbCut4ccXDyEgwM7aT+eBy9O5KSuVp1bksTK33OlyzAks3I1pY/7nu0mMDmN2pvXe7YiI8J/Xnkta3wge+zCX5hZrnvEkFu7GuKzdV0l2fiV3XziYkCD71eiM4MAA/umKEewoq+XNdUVOl2PasE+wMS7zV+6mT0QwcyZ67hJ6nmjmqP6MSY3hiU93cqzR+k54Cgt3Y4Dc/TUszy3njimDiAixyVLPhIjw8IwRlFYfY8HXe50ux7hYuBsDPPP5bnqFBDJ3cprTpXilyUP6MnV4PPNX5lFV1+B0OQYLd2MoOFjHextLuGXSQKIjfG8JvZ7yyytHUFvfxPzPdztdisHC3Rhe+HIPQQEB3OXjS+i524j+UVw3NoUFX++luOqo0+X4PQt349dqjzXy1roirh6TREJUmNPleL0Hp7eu2PT4JzscrsRYuBu/9s76Yo40NPPDyQOdLsUnJMeEc8f5aby9vpjtpTVOl+PXLNyN31JVXv22gFHJ0YxJjXG6HJ9x7yVD6B0axH9/lOt0KX7Nwt34rTV7D7GjrJbbJtlZe3eKiQhh3tShfL6jgq93H3C6HL9l4W781qvf7iMqLIirxyQ5XYrPmXt+GknRYTz2Ya7NGukQC3fjlypq6/lwSynXj08lPCTQ6XJ8TlhwIA9OH86momre31zqdDl+ycLd+KWlOYU0Niu3TBrgdCk+69qxyYzo35vffLyDhiZb1KOnWbgbv9Pcory+uoApQ/syJD7S6XJ8VmCA8MsZI9h3sI7FawqcLsfvWLgbv7Myt5ziqqPcep5dSHW3S4bHM2lwLE9+tovDtuZqj+rMGqphIpItIhtFZKuI/Nq1PVZEPhWRXa7bPm2OeURE8kRkh4hc4c4fwJgz9erqfSREhXL5yASnS/F5IsLDV57DwSMNPP/FHqfL8SudOXOvBy5V1TFAJjBDRCYBDwPLVTUdWO56jIiMBOYAGcAMYL6I2BUr4xEKDtaxamcFcyYMIDjQ/nHtCZmpMVw1KpEXv9xDee0xp8vxGx1+urXVYdfDYNeXArOAha7tC4HZrvuzgMWqWq+q+UAeMLE7izbmbL2WvY8AEW6eaBdSe9LPrxhOQ1MLTy3f5XQpfqNTpy4iEigiG4By4FNVXQ0kqGopgOu2n2v3ZKCwzeFFrm3GOOpYYzNL1xQyfWQC/aNtHpmeNCiuFzdPHMCi7EL2VBzu+ADTZZ0Kd1VtVtVMIAWYKCLnnmb39lYVPmkUg4jcIyI5IpJTUVHRqWKN6YoPt5RyqK6RW21EqiN+elk6YUEB/NYmFesRZ9ToqKpVwOe0tqWXiUgigOv2+PLnRUDbdcpSgJJ2vtfzqpqlqlnx8fFnXrkxZ+iVb/YxOL4X5w/p63Qpfim+dyh3XzSYDzbvZ33BIafL8Xmd6S0TLyIxrvvhwOVALrAMmOvabS7wruv+MmCOiISKyCAgHcju5rqNOSNbS6pZV1DFLecNRKS9fy5NT/jRhYOJiwzhv2xaArfrzJl7IrBSRDYBa2htc/8L8BgwTUR2AdNcj1HVrcBSYBvwETBPVW3VXOOoV78tICw4gOvHpThdil+LDA3i/svSyc6vZOWO8o4PMGetw5WAVXUTMLad7QeBy05xzKPAo12uzphuUHOskXc3FHPNmCRbRs8DzJk4gBe/yue3H+9k6vB+9p+Um1hHX+Pz3l5XTF1DM7dNSnO6FAMEBwbw00vT2VZaw8dby5wux2dZuBuf1rogxz7GpEQzKiXa6XKMy6zMJAbH9+L3n+2kpcXa3t3Bwt34tNX5lewqP2zdHz1MUGAA91+WTu7+Wj7YYlMCu4OFu/Fpr3y7j+jwYFuQwwN9b3QS6f0i+f1nu2i2s/duZ+FufFZ57TE+3rKfG8anEBZs0xt5msAA4YHLh5FXfpi/bDppKIzpIgt347OWZBfS1KLcYk0yHuvKc/szon9vnvxsF03NtqBHd7JwNz6pqbmFRdkFXJgex6C4Xk6XY04hIED42bRh7DlwhHc22Nl7d7JwNz5pRW45JdXH7EKqF5g+MoGMpCieWr6LRjt77zYW7sYnvbq6gMToMC4b0a/jnY2jRIQHpw2joLKOt9YVOV2Oz7BwNz5n74EjfLGzgpsnDiDIFuTwCpeO6MeY1BieWp5ni2l3E/vkG5/zenYBQQHCnAmpHe9sPMLxs/fiqqMszSns+ADTIQt341OONTazNKeQKzL60y/KFuTwJhelxzF+YB+eXpnHsUaba7CrLNyNT3l/UylVdY3cMsmW0fM2x8/eS6uPsWSNnb13lYW78Smvrd7HkPheTB5sC3J4o/OH9OW8QbF29t4NLNyNzyirOca6giquG5di08h6KZHWfu/ltfW8+u0+p8vxahbuxmeszG1d/OGyc6z7ozebNLgvU4b25dlVu6lraHK6HK9l4W58xorccpJjwhme0NvpUkwXPThtGAcON/DKN3b2frY6s4ZqqoisFJHtIrJVRO53bf+ViBSLyAbX18w2xzwiInkiskNErnDnD2AMtPaS+SrvAFNHxFuTjA8YPzCWi4fF8+yq3Ryut7P3s9GZM/cm4CFVPQeYBMwTkZGu555Q1UzX1wcArufmABnADGC+iNiUfMatVudXUtfQzGUjEpwuxXSTn00bxqG6RhZ+vdfpUrxSh+GuqqWqus51vxbYDiSf5pBZwGJVrVfVfCAPmNgdxRpzKitzywkLDmDyEOsl4ysyU2O4bEQ/nv9iDzXHGp0ux+ucUZu7iKTRulj2atemn4jIJhF5SUT6uLYlA207qRZx+j8GxnSJqrI8t4wLhsbZvO0+5mfThlF9tJGXv9rrdClep9PhLiKRwJvAA6paAzwDDAEygVLg8eO7tnP4ScusiMg9IpIjIjkVFRVnWrcxf5NXfpjCyqNMtUnCfM65ydFckZHAi1/tobrOzt7PRKfCXUSCaQ3211T1LQBVLVPVZlVtAV7gu6aXIqDtpB4pwEkTNavq86qapapZ8fHxXfkZjJ9b4eoCeamFu0964PJh1B5r4sWv9jhdilfpTG8ZAf4IbFfV37XZnthmt2uBLa77y4A5IhIqIoOAdCC7+0o25u8tzy1nZGIUidHhTpdi3OCcxCiuGpXIS1/lc+hIg9PleI3OnLlPAW4DLj2h2+P/iMhmEdkETAV+BqCqW4GlwDbgI2Ceqto4YuMWVXUNrN13yM7afdz9l6dT19jM81/a2XtnBXW0g6p+Rfvt6B+c5phHgUe7UJcxnbJqZwXNLcqlNirVpw1L6M3MUYm8+u0+fjJ1KL1CO4wuv2cjVI1XW5lbTt9eIYxJiXG6FONmd04ZRO2xJlutqZMs3I3Xampu4fOdFVw8PJ7AABuV6uvGDYhhTEo0L3+9l5aWkzrgmRNYuBuvtb6wiqq6RhuV6idEhDumDGJPxRG+2GXdpzti4W681orccoIChAuHxTldiukhM0cl0q93KC//da/TpXg8C3fjtVZsL2dCWixRYcFOl2J6SEhQALdOGsiqnRXklR92uhyPZuFuvFLRoTp2lNXa3O1+6AfnDSAkMMAmFOuAhbvxSittVKrfiosM5ZrMJN5cV0T1UZuS4FQs3I1XWp5bTlrfCAbHRzpdinHAHVPSqGtoZqktpH1KFu7G69Q1NPH17oNcar1k/FZGUjQTB8Wy4Ou9NDW3OF2OR7JwN17n67yDNDS1WHu7n7tzShrFVUf5bHuZ06V4JAt343WW55YTGRrEhLRYp0sxDpo2sj/JMeG8ZN0i22XhbryKqrIit4wL0+MICbKPrz8LDBDmnj+Q7PxKtpZUO12Ox7HfDuNVtpbUUFZTb71kDAA3ZQ0gPDjQBjW1w8LdeJWVueWIwCXDLdwNREcE8/3xySzbUMKBw/VOl+NRLNyNV1meW87olBjie4c6XYrxELefP4iG5hZeX13gdCkexcLdeI0Dh+vZWFTFZdYkY9oY2i+Si4bF88q3+2hosm6Rx1m4G6/x+Y4KVG1UqjnZHVPSqKit54PNpU6X4jE6s4ZqqoisFJHtIrJVRO53bY8VkU9FZJfrtk+bYx4RkTwR2SEiV7jzBzD+Y0VuGQlRoWQkRTldivEwF6fHMziuFy//NR9Vm+sdOnfm3gQ8pKrnAJOAeSIyEngYWK6q6cBy12Ncz80BMoAZwHwRCXRH8cZ/NDS18MXOA1w6oh+ta7Yb852AAOGOKWlsLKpmXUGV0+V4hA7DXVVLVXWd634tsB1IBmYBC127LQRmu+7PAharar2q5gN5wMRurtv4mZy9lRyub7IpB8wpXTcuhd5hQbz813ynS/EIZ9TmLiJpwFhgNZCgqqXQ+gcAON4Qmgy0nc2nyLXNmLO2PLeckKAApgzt63QpxkP1Cg1izoRUPtyyn9Lqo06X47hOh7uIRAJvAg+oas3pdm1n20mNYCJyj4jkiEhORYUtmWVOb0VuOZMH9yUixFa9N6f2w8lpqCqvfLPP6VIc16lwF5FgWoP9NVV9y7W5TEQSXc8nAuWu7UVAapvDU4CSE7+nqj6vqlmqmhUfH3+29Rs/sKfiMPkHjthEYaZDqbERTBuZwKLsAo41NjtdjqM601tGgD8C21X1d22eWgbMdd2fC7zbZvscEQkVkUFAOpDdfSUbf7PCtTDHVBuVajrhjimDOFTXyDvri50uxVGdOXOfAtwGXCoiG1xfM4HHgGkisguY5nqMqm4FlgLbgI+Aearq339CTZesyC1nWEIkqbERTpdivMB5g2I5JzGKl/+616+7RXbYgKmqX9F+OzrAZac45lHg0S7UZQwANccayc6v5EcXDna6FOMlRFq7Rf7iz5v4ZvdBzh8a53RJjrARqsajfbXrAE0tau3t5oxcMyaJvr1C/Hqudwt349GWby8nOjyYsakxTpdivEhYcCA/OG8Ay3PL2HfwiNPlOMLC3Xislhbl8x3lXDI8nqBA+6iaM3PrpIEEirDwa//sFmm/McZjbSyq4uCRBpsozJyVhKgwrhqdyOI1BX559m7hbjzWitxyAgQuHmbjIMzZ+cWMEQQFCD9dvIHGZv+aDtjC3Xis5dvLyRoYS0xEiNOlGC+VHBPOf39/NBsLq/jdpzudLqdHWbgbj1RYWce20hqmWpOM6aIrRyVy88RUnl21m7/mHXC6nB5j4W480p/XFiECV49JdLoU4wP+7/cyGBIfyc+WbOCgn6y1auFuPE5zi/LntUVcMDSOlD42KtV0XXhIIE/NGUtVXSO/fHOTX4xctXA3HueveQcorjrKjVmpHe9sTCeNTIrikZkj+Gx7OX/yg1kjLdyNx1mSU0hMRDDTM2xhDtO9bj8/jUtH9OPRD7azvfR0M5d7Pwt341EOHWng061lzM5MJjTIVmc03UtE+M31o4kJD+YfF63naIPvzmlo4W48ytvri2lobuGmCdYkY9yjb2Qov7sxk90Vh/mP97c5XY7bWLgbj6GqLM0pZHRKNOckRjldjvFhF6THcc9Fg3l9dQEfbSl1uhy3sHA3HmNTUTW5+2vtQqrpEQ9NG86YlGh++eZmSqp8b81VC3fjMZbkFBIWHMA1mUlOl2L8QEhQAE/dPJam5hYeWLyB5hbf6h5p4W48wtGGZt7bUMLMcxOJCgt2uhzjJwb27cV/zD6X7L2V/O+KPKfL6VadWUP1JREpF5Etbbb9SkSKT1h27/hzj4hInojsEJEr3FW48S0fbC6ltr6JG+1Cqulh141L4dqxyTy5fCc5eyudLqfbdObMfQEwo53tT6hqpuvrAwARGQnMATJcx8wXEevPZjq0JKeQtL4RnDco1ulSjB/691kZpPSJ4P7FG6g+2uh0Od2iw3BX1S+Azv45mwUsVtV6Vc0H8oCJXajP+IH8A0fIzq/khqxURE61XK8x7tM7LJinbh5LWc0x/vmtzT4xPUFX2tx/IiKbXM02fVzbkoHCNvsUubYZc0pv5BQSIHD9+BSnSzF+LDM1hoemD+f9zaUszSns+AAPd7bh/gwwBMgESoHHXdvbO+1q90+giNwjIjkiklNRUXGWZRhv19Tcwp/XFjF1eD8SosKcLsf4uX+4aDBThvblV8u2saGwyulyuuSswl1Vy1S1WVVbgBf4rumlCGh7RSwFKDnF93heVbNUNSs+3lba8VerdlZQXltvF1KNRwgIEJ64MZN+UaHc9uJqrw74swp3EWk7yfa1wPGeNMuAOSISKiKDgHQgu2slGl+2ZE0hcZGhtk6q8Rj9osJYdPckYiNDvDrgO9MVchHwDTBcRIpE5C7gf0Rks4hsAqYCPwNQ1a3AUmAb8BEwT1V9d2Ye0yUVtfWsyC3n++OSCQ60IRfGcyTFhHt9wIsnXBXOysrSnJwcp8swPey5Vbv5rw9z+ezBixnaL9Lpcow5SUnVUW5+4VsqDzfwyo/OIzM1xumS/o6IrFXVrPaes9Ml4whVZUlOIVkD+1iwG4/lzWfwFu7GEWv3HWJPxRG7kGo8nrcGvIW7ccSSNYX0CgnkqlG2ALbxfN4Y8Bbupscdrm/i/c2lXD0miV6hQU6XY0yneFvAW7ibHveXjSXUNTRzg83bbryMNwW8hbvpcUtyChnaL5JxA2KcLsWYM+YtAW/hbnrUrrJa1hdUcZNNEma8mDcEvIW76VFL1hQSFCBcO87mkzPezdMD3sLd9JiGphbeWl/M5eckEBcZ6nQ5xnTZiQG/pbja6ZL+xsLd9Jjl28uoPNLATda33fiQ4wHfOyyIf3hlLYeONDhdEmDhbnrQkpxC+keFcdEwmwXU+JakmHCeuXU8FbX1PLDEMxbbtnA3PaK0+ihf7Kzg+vEpBAbYhVTje8akxvBv14xk1c4K/rBil9PlWLibnvHnnCJaFG60vu3Gh/1g4gCuG5fMk8t38fmOckdrsXA3btfSoixdW8jkwX0Z0DfC6XKMcRsR4dHZoxie0JsHlmygsLLOsVos3I3bfbvnIIWVR+1CqvEL4SGBPHvreJpblPteW8exRmeWtLBwN263JKeQqLAgZpzb3+lSjOkRaXG9ePyGMWwurubX721zpAYLd+NWVXUNfLhlP9eOTSYsONDpcozpMdMz+nPvJUNYlF3AGzmFPf76Fu7Grd5ZX0xDUws3TRjgdCnG9LiHpg3j/CF9+dd3trC1pGcHOHVmDdWXRKRcRLa02RYrIp+KyC7XbZ82zz0iInkiskNErnBX4cbzqSqL1xQyOiWakUlRTpdjTI8LCgzgqZvH0icihHtfXUd1XWOPvXZnztwXADNO2PYwsFxV04HlrseIyEhgDpDhOma+iNj/4n5qU1E1uftr7UKq8WtxkaE8fcs4SqqO8uDSDbT00ACnDsNdVb8AKk/YPAtY6Lq/EJjdZvtiVa1X1XwgD5jYPaUab7N4TSHhwYFcMybJ6VKMcdT4gX3416vOYXluOc+s2t0jr3m2be4JqloK4Lrt59qeDLS9clDk2nYSEblHRHJEJKeiouIsyzCe6kh9E8s2FHPV6ER6hwU7XY4xjpt7fhrXjEni8U928NWuA25/ve6+oNreuPJ2/wdR1edVNUtVs+Ljba4RX/P+plKONDQzx5pkjAFaBzj913WjGBIfyU8Xr6ek6qhbX+9sw71MRBIBXLfHx9kWAW1/m1OAkrMv7/QOHWngRwtzHB0FZtq3eE0BQ+J7MX5gn453NsZP9AoN4tnbxlPf2Mx9r62jvsl9A5zONtyXAXNd9+cC77bZPkdEQkVkEJAOZHetxFMrOnSUNXsruXb+1x41j7K/21lWy7qCKuZMGGCrLRlzgiHxkfzmhjFsKKzi0fe3u+11OtMVchHwDTBcRIpE5C7gMWCaiOwCprkeo6pbgaXANuAjYJ6quu1P06iUaN68dzKhQQHc9Nw3fLHT2u49wZI1hQQH2mpLxpzKzFGJ3H3hIP70zT7eWV/sltfoTG+Zm1U1UVWDVTVFVf+oqgdV9TJVTXfdVrbZ/1FVHaKqw1X1Q7dU3cbQfr15677zSY2N4M4Fa3hzbZG7X9KcRn1TM2+tK2LaSFttyZjT+cWMEUxMi2V1/omdEbtHkFu+aw9LiApj6Y8nc++ra3nojY3srznGfZcMsSYBB3y6rYxDdY02ItWYDgQHBrDgzgmEu2laDp+ZfiAqLJiXb5/I7MwkfvPxDv7Pu1s8YjUUf7NkTSHJMeFcMDTO6VKM8XgRIUFuOwn1iTP340KCAvjdjZkkRIfx3Ko9lNfU89TNY23Cqh5SWFnHl7sO8MDl6bbakjEO85kz9+MCAoRHrjyHf7t6JJ9uL+MHL3zrMQvW+ro3cgoRgRtstSVjHOdz4X7cHVMGMf8H49hSUsP3n/3a+sK7WXOLsjSniIvS40mOCXe6HGP8ns+GO8CVoxJ59a7zOFBbz3XPWF94d/piZwX7a47ZiFRjPIRPhzvAxEGxvHnv+QQHCDc99w1f7rK+8O6weE0BfXuFcNk5CU6XYozBD8IdID2hN2/dN4XU2AjueHkNb62zvvDdqbz2GMu3l/P98SmEBPnFR8oYj+c3v4n9o1v7wk9Ii+XBpRv5zce5NDa3OF2WT3hrXTFNLcqNdiHVGI/hN+EOrX3hF9w5gZuyUnl65W5uePYb9h084nRZXk1VWbKmkAlpfRjaL9LpcowxLn4V7gChQYH89/WjefoH49hTcZiZT37Jn9cWoWoDns5Gdn4l+QeO2IhUYzyM34X7cVeNTuTDBy4iIzman7+xkX9ctJ7qoz23vqGvWLKmkN6hQcwc1d/pUowxbfhtuAMkx4Sz6O5J/NMVw/lwy35mPvkl2W6axMcXVR9t5P3NpVyTmUREiE8NdjbG6/l1uAMEBgjzpg7lzXvPJyhQmPP8N/zukx002cXWDi3bUEx9UwtzrEnGGI/j9+F+XGZqDO//9EKuG5fCUyvyuOG5byg4aKNaT2fxmkIykqIYlRLtdCnGmBNYuLcRGRrEb28Ywx9uHkte+WFmPvUlb62zi63t2VJczdaSGhuRaoyHsnBvx9Vjkvjw/gsZmRjFg0s3cv/iDdQcs4utbS1eU0BoUADXZNpqS8Z4oi6Fu4jsFZHNIrJBRHJc22JF5FMR2eW69coVklP6RLDonkk8NG0Y728u5crff8m6gkNOl+UR6hqaeHd9CVeNSiQ6PNjpcowx7eiOM/epqpqpqlmuxw8Dy1U1HVjueuyVAgOEf7wsnTd+PJnAAOG2F1ezucgmH/tg835q65u4yZpkjPFY7miWmQUsdN1fCMx2w2v0qHED+vDGjycTExHCHQuy/X5U65I1BQyK68XEQbFOl2KMOYWuhrsCn4jIWhG5x7UtQVVLAVy3/do7UETuEZEcEcmpqPD8mRoTosL4010TaW5RfvhSNhW19U6X5Ii88sOs2XuImyak2hq1xniwrob7FFUdB1wJzBORizp7oKo+r6pZqpoVHx/fxTJ6xpD4SF66fQLlNfXcsSCbw/VNTpfUo1palCc+20lQgHDdOLuQaown61K4q2qJ67YceBuYCJSJSCKA67a8q0V6krED+vD0LWPZXlrLva+upaHJPwY7qSr//pdtvL+plAcuT6df7zCnSzLGnMZZh7uI9BKR3sfvA9OBLcAyYK5rt7nAu10t0tNcOiKBx64bxZe7DvCLP2+kpcX3+8E/uXwXC77ey10XDGLe1KFOl2OM6UBXJgRJAN52tbsGAa+r6kcisgZYKiJ3AQXADV0v0/PckJVKeW09v/l4B/G9Q/mXq0Y6XZLbvPzXfH7/2S6uH5/Cv8w8x9rajfECZx3uqroHGNPO9oPAZV0pylvcd8kQymuO8cKX+fTrHcbdFw12uqRu9+baIn793jauyGj9byUgwILdGG9gU/l1gYjwf6/O4MDhBh79YDvxvUOZPdZ3LjR+snU/v3hzE1OG9uXJOWMJCrQBzcZ4Cwv3LgoMEB6/cQwHj9Tz8zc2EtsrhIuGeUfvn9P5evcBfrJoPecmR/PcbVmEBQc6XZIx5gzYqVg3CAsO5PkfZjG0XyT3vrrW60exbiys4u6FOaT1jWDB7ROIDLVzAGO8jYV7N4kKC2bhnROJiQjh9pez2XvAO0ex7iqr5faXs+nTK4RX7jqPPr1CnC7JGHMWLNy70fFRrC3qnaNYCyvruO2P2QQFBvDaj84jIcr6shvjrSzcu9mQ+Ej+ePsEymuPedUo1oraem7742rqGpr4050TGdi3l9MlGWO6wMLdDcYN6MP8W8axvbSWuxfmcOCwZ5/BVx9t5IcvZVNWU8/Ld0zknMQop0syxnSRhbubXDoigd9cP5q1+w4x/Ykv+MumEqdLalddQxN3LlhDXnktz902nvEDvXL6fWPMCSzc3ei6cSn85acXkNInnJ+8vp55r63joAedxTc0tXDvq+tYX3CIJ+eM9YkunMaYVhbubjYsoTdv3Xs+/3TFcD7Ztp/pT3zBh5tLHa1JVflq1wHmvpTNqp0V/L9rRzFzVKKjNRljupd4wuLPWVlZmpOT43QZbrdjfy0/f2Mjm4ur+d7oRP591rnE9mBXw5pjjby5tohXvt3HnoojxPYK4aHpw7jlvIE9VoMxpvuIyNo2q+D9/XMW7j2rsbmFZz/fzVMrdhEdHsx/zh7FjHP7u/U1c/fX8Kdv9vHO+mLqGprJTI3hh5MHMnNUoo08NcaLWbh7oO2lNfz8jY1sLanhmjFJ/PqajG4dMNTY3MLHW/fzp2/2kZ1fSWhQANeMSeKHk9MYlRLdba9jjHGOhbuHamxuYf7K3fxhxS5iIkL4f9eey/SMrp3Fl9Uc4/XVBSzKLqC8tp7U2HBuPW8gN2al2mhTY3yMhbuH21bSeha/rbSG2ZlJ/OqaDGIi/j6IVZX6phbqG1uob2rm2Am3h+oaeWd9MR9v3U+zKhcPi+eHkwdy8bB+BNo0vcb4JAt3L9DY3MLTK/P43xV5RIQEEh0R3Brcjc0ca2rp1HJ+0eHB3JiVwq2TBtoIU2P8wOnC3ab78xDBgQE8cPkwpo1M4KWv9qIooUGBhAYFEBbcehsaHEBYUCChwQEnPRcWHMio5GjCQ+wCqTHGjeEuIjOAJ4FA4EVVfcxdr+VLMpKiefzGkxa4MsaYM+KWQUwiEgg8DVwJjARuFhHfXWTUGGM8jLtGqE4E8lR1j6o2AIuBWW56LWOMMSdwV7gnA4VtHhe5tv2NiNwjIjkiklNRUeGmMowxxj+5K9zb63v3d91yVPV5Vc1S1az4eJuwyhhjupO7wr0ISG3zOAXwzDlvjTHGB7kr3NcA6SIySERCgDnAMje9ljHGmBO4pSukqjaJyE+Aj2ntCvmSqm51x2sZY4w5mdv6uavqB8AH7vr+xhhjTs0jph8QkQpgXxe+RRxwoJvK8Wb2PrSy96GVvQ+tfPl9GKiq7fZI8Yhw7yoRyTnV/Ar+xN6HVvY+tLL3oZW/vg+2zJ4xxvggC3djjPFBvhLuzztdgIew96GVvQ+t7H1o5Zfvg0+0uRtjjPl7vnLmbowxpg2vDncRmSEiO0QkT0Qedroep4jIXhHZLCIbRMSvlrQSkZdEpFxEtrTZFisin4rILtdtHydr7AmneB9+JSLFrs/FBhGZ6WSNPUFEUkVkpYhsF5GtInK/a7vffSa8NtxtzviTTFXVTD/s8rUAmHHCtoeB5aqaDix3PfZ1Czj5fQB4wvW5yHQNLPR1TcBDqnoOMAmY58oFv/tMeG24Y3PGG0BVvwAqT9g8C1jour8QmN2TNTnhFO+D31HVUlVd57pfC2yndbpxv/tMeHO4dzhnvB9R4BMRWSsi9zhdjAdIUNVSaP1lB/o5XI+TfiIim1zNNj7fFNGWiKQBY4HV+OFnwpvDvcM54/3IFFUdR2sT1TwRucjpgoxHeAYYAmQCpcDjjlbTg0QkEngTeEBVa5yuxwneHO42Z7yLqpa4bsuBt2ltsvJnZSKSCOC6LXe4HkeoapmqNqtqC/ACfvK5EJFgWoP9NVV9y7XZ7z4T3hzuNmc8ICK9RKT38fvAdGDL6Y/yecuAua77c4F3HazFMcfDzOVa/OBzISIC/BHYrqq/a/OU330mvHoQk6tr1+/5bs74R52tqOeJyGBaz9ahdQrn1/3pfRCRRcAltM78Vwb8G/AOsBQYABQAN6iqT19sPMX7cAmtTTIK7AX+4Xi7s68SkQuAL4HNQItr8z/T2u7uX58Jbw53Y4wx7fPmZhljjDGnYOFujDE+yMLdGGN8kIW7Mcb4IAt3Y4zxQRbuxi+JSFrbGRSN8TUW7sZ0ExEJcroGY46zcDf+LFBEXnDN+/2JiISLSKaIfOuabOvt45NticjnIpLluh8nIntd928XkTdE5D3gE+d+FGP+noW78WfpwNOqmgFUAd8H/gT8UlVH0zrK8d868X0mA3NV9VJ3FWrMmbJwN/4sX1U3uO6vpXUGxRhVXeXathDozAybn/r6UHbjfSzcjT+rb3O/GYg5zb5NfPf7EnbCc0e6sSZjuoWFuzHfqQYOiciFrse3AcfP4vcC4133r+/huow5Y3Z135i/Nxd4VkQigD3AHa7tvwWWishtwAqnijOms2xWSGOM8UHWLGOMMT7Iwt0YY3yQhbsxxvggC3djjPFBFu7GGOODLNyNMcYHWbgbY4wPsnA3xhgf9P8B6mS6/vYgM+sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.2 - \"workingday\"=0 escriba su código y hallazgos \n",
    "bikes[bikes['workingday']==0].groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='hour'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.3 - \"workingday\"=1 escriba su código y hallazgos \n",
    "bikes[bikes['workingday']==1].groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las gráficas anteriores se encuentran los siguientes hallazgos:\n",
    "\n",
    "* `hour`\n",
    "\n",
    "En concordancia con lo descrito en el punto anterior, se muestra la presencia de dos picos de demanda en los horarios comprendidos entre las 8:00 - 9:00 y las 16:00 - 19:00 para el alquiler de bicicletas. Del mismo modo la gráfica hace más evidente la disminución en los alquileres para la franja de 3:00 - 5:00. En los horarios que se pueden considerar como inicio y fin de jornadas se ven estos incrementos en los alquileres, mientras que en las franjas de medio dia y nocturnas hay una evidente disminución.\n",
    "\n",
    "* `workingday == 0`\n",
    "\n",
    "Cuando la observación corresponde a un día feriado o fin de semana, se muestra un comportamiento diferente al evidenciado en la primera gráfica. En términos generales se puede ver que las diminuciones en las franjas de medio día que se veían antes han cmabiado por el contrario a ser el pico de la solicitud de alquileres de bicicletas. Se mantiene la tendencia a disminuir en cantidad de alquileres en el periodo de 3:00 a 6:00.\n",
    "\n",
    "* `workingday == 1`\n",
    "\n",
    "Cuando es un día 'laboral' u 'habitual', el comportamiento que se muestra en la gráfica es muy similar al comportamiento sin discriminar. Esto puede ser debido a que hay una dominancia en esta categoría respecto a la cantidad de observaciones que son de días feriados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Regresión lineal\n",
    "En la celda 3 ajuste un modelo de regresión lineal a todo el conjunto de datos, utilizando \"total\" como variable de respuesta y \"hour\" y \"workingday\" como las únicas variables predictoras. Luego, imprima los coeficientes e interprételos. ¿Cuáles son las limitaciones de la regresión lineal en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los coeficientes de las variables predictoras del modelo son:  [10.49206282  4.07248627]\n",
      "El intercepto del modelo es:  67.70595026191576\n",
      "El valor del R_cuadrado del modelo es:  0.16059115011434866\n",
      "El RMSE del modelo lineal es:  165.95558216733295\n"
     ]
    }
   ],
   "source": [
    "# Celda 3\n",
    "X = bikes.loc[:,['hour','workingday']]\n",
    "y = bikes.total\n",
    "\n",
    "lr =  LinearRegression().fit(X, y)\n",
    "y_pred_lr = lr.predict(X)\n",
    "print('Los coeficientes de las variables predictoras del modelo son: ', lr.coef_)\n",
    "print('El intercepto del modelo es: ', lr.intercept_)\n",
    "\n",
    "print('El valor del R_cuadrado del modelo es: ',r2_score(y, y_pred_lr))\n",
    "print('El RMSE del modelo lineal es: ', np.sqrt(mean_squared_error(y, y_pred_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución\n",
    "\n",
    "1. **Procedimiento**\n",
    "\n",
    "En el código anterior se procede a establecer como variables predictoras, conjunto de variables $X$ las indicadas en enunciado: `hour` y `workingday` y target $y$ será `total`. Una vez declaradas las variables, se procede a entrenar una regresión lineal por mínimos cuadrados usando la librería. Se genera un conjunto de predicciones \n",
    "\n",
    "2. **Análisis**\n",
    "\n",
    "La ecuación de regresión del modelo lineal implementado anteriormente es:\n",
    "\n",
    "$$\\hat{Total} = \\hat\\beta_0 + \\hat\\beta_1 X_1 + \\hat\\beta_2 X_1$$\n",
    "\n",
    "$$\\hat{Total} = \\hat\\beta_0 + \\hat\\beta_1 hour  + \\hat\\beta_2 workingday $$\n",
    "\n",
    "$$\\hat{Total} = 67.706 + 10.492*hour  + 4.072*workingday $$\n",
    "\n",
    "Se pueden interpretar los coeficientes de la siguiente forma:\n",
    "\n",
    "* `hour`: por cada incremento de una unidad en esta variable se incrementa en 10.492 el total de alquileres de bicicletas.\n",
    "* `workingday`: por cada incremento de una unidad en esta variable se incrementa en 4.072 el total de alquileres de bicicletas.\n",
    "\n",
    "*Limitaciones*\n",
    "\n",
    "El modelo lineal planteado es altamente interpretable como se demuestra con las ecuaciones y estimadores descritos arriba, sin embargo, dado que el $R^2$ es de 0.16, es posible indicar que la baja flexibilidad de la regresión no es capaz de explicar la varianza del fenómeno de análisis (cantidad de alquileres de ciclas), con el RMSE (Raiz del Error Cuadrático Medio) también es posible ver habrá un error esperado en cada predicción alrededor de 165.9 alquileres. En general el modelo carga demasiado sesgo para ser un buen estimador de los alquileres, sería prudente explorar otras alternativas así como incluir otros predictores de los disponibles en el conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Árbol de decisión manual\n",
    "En la celda 4 cree un árbol de decisiones para pronosticar la variable \"total\" iterando **manualmente** sobre las variables \"hour\" y  \"workingday\". El árbol debe tener al menos 6 nodos finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El R_cuadrado del modelo basado en árboles es:  0.6479944604591312\n",
      "El MSE del modelo de árboles es:  11549.40696194607\n",
      "El RMSE del modelo de árboles es:  107.46816720287953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'y_pred': 191.57413191254824,\n",
       " 'y_prob': 191.53903379867745,\n",
       " 'level': 0,\n",
       " 'split': [0, 8.0],\n",
       " 'n_samples': 10886,\n",
       " 'gain': 9134.40591176651,\n",
       " 'sl': {'y_pred': 55.437673900946024,\n",
       "  'y_prob': 55.40711902113459,\n",
       "  'level': 1,\n",
       "  'split': [0, 7.0],\n",
       "  'n_samples': 3594,\n",
       "  'gain': 3603.8503299798276,\n",
       "  'sl': {'y_pred': 32.58203249442498,\n",
       "   'y_prob': 32.561604584527224,\n",
       "   'level': 2,\n",
       "   'split': [0, 6.0],\n",
       "   'n_samples': 3139,\n",
       "   'gain': 323.4004463794779,\n",
       "   'sl': {'y_pred': 25.177719821162444,\n",
       "    'y_prob': 25.15934475055845,\n",
       "    'level': 3,\n",
       "    'split': [0, 2.0],\n",
       "    'n_samples': 2684,\n",
       "    'gain': 191.40441543023144,\n",
       "    'sl': {'y_pred': 44.51045104510451,\n",
       "     'y_prob': 44.41383095499451,\n",
       "     'level': 4,\n",
       "     'split': [1, 1.0],\n",
       "     'n_samples': 909,\n",
       "     'gain': 701.2852140818158,\n",
       "     'sl': {'y_pred': 83.2,\n",
       "      'y_prob': 82.63356164383562,\n",
       "      'level': 5,\n",
       "      'split': [0, 1.0],\n",
       "      'n_samples': 290,\n",
       "      'gain': 127.45631391200982,\n",
       "      'sl': {'y_pred': 94.48965517241379,\n",
       "       'y_prob': 93.21088435374149,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 145,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 71.9103448275862,\n",
       "       'y_prob': 70.93877551020408,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 145,\n",
       "       'gain': 0}},\n",
       "     'sr': {'y_pred': 26.38449111470113,\n",
       "      'y_prob': 26.30112721417069,\n",
       "      'level': 5,\n",
       "      'split': [0, 1.0],\n",
       "      'n_samples': 619,\n",
       "      'gain': 107.4228060284205,\n",
       "      'sl': {'y_pred': 36.73225806451613,\n",
       "       'y_prob': 36.5,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 310,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 16.003236245954692,\n",
       "       'y_prob': 15.903536977491962,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 309,\n",
       "       'gain': 0}}},\n",
       "    'sr': {'y_pred': 15.27718309859155,\n",
       "     'y_prob': 15.260551491277434,\n",
       "     'level': 4,\n",
       "     'split': [1, 1.0],\n",
       "     'n_samples': 1775,\n",
       "     'gain': 38.681225587817096,\n",
       "     'sl': {'y_pred': 24.273519163763066,\n",
       "      'y_prob': 24.19097222222222,\n",
       "      'level': 5,\n",
       "      'split': [0, 3.0],\n",
       "      'n_samples': 574,\n",
       "      'gain': 288.2428308876518,\n",
       "      'sl': {'y_pred': 53.74825174825175,\n",
       "       'y_prob': 53.01379310344828,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 143,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 14.494199535962878,\n",
       "       'y_prob': 14.429561200923787,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 431,\n",
       "       'gain': 61.15892798172911}},\n",
       "     'sr': {'y_pred': 10.97751873438801,\n",
       "      'y_prob': 10.960099750623442,\n",
       "      'level': 5,\n",
       "      'split': [0, 5.0],\n",
       "      'n_samples': 1201,\n",
       "      'gain': 63.89392909375985,\n",
       "      'sl': {'y_pred': 6.262626262626263,\n",
       "       'y_prob': 6.249720044792833,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 891,\n",
       "       'gain': 2.458653112567003},\n",
       "      'sr': {'y_pred': 24.529032258064515,\n",
       "       'y_prob': 24.375,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 310,\n",
       "       'gain': 0}}}},\n",
       "   'sr': {'y_pred': 76.25934065934067,\n",
       "    'y_prob': 75.92778993435448,\n",
       "    'level': 3,\n",
       "    'split': [1, 1.0],\n",
       "    'n_samples': 455,\n",
       "    'gain': 1480.8192588203644,\n",
       "    'sl': {'y_pred': 19.99310344827586,\n",
       "     'y_prob': 19.727891156462587,\n",
       "     'level': 4,\n",
       "     'split': -1,\n",
       "     'n_samples': 145,\n",
       "     'gain': 0},\n",
       "    'sr': {'y_pred': 102.57741935483871,\n",
       "     'y_prob': 101.92307692307692,\n",
       "     'level': 4,\n",
       "     'split': -1,\n",
       "     'n_samples': 310,\n",
       "     'gain': 0}}},\n",
       "  'sr': {'y_pred': 213.11648351648353,\n",
       "   'y_prob': 212.18599562363238,\n",
       "   'level': 2,\n",
       "   'split': [1, 1.0],\n",
       "   'n_samples': 455,\n",
       "   'gain': 12865.428670463856,\n",
       "   'sl': {'y_pred': 47.26896551724138,\n",
       "    'y_prob': 46.63265306122449,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 145,\n",
       "    'gain': 0},\n",
       "   'sr': {'y_pred': 290.69032258064516,\n",
       "    'y_prob': 288.83012820512823,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 310,\n",
       "    'gain': 0}}},\n",
       " 'sr': {'y_pred': 258.6715578716402,\n",
       "  'y_prob': 258.6007677543186,\n",
       "  'level': 1,\n",
       "  'split': [0, 21.0],\n",
       "  'n_samples': 7292,\n",
       "  'gain': 3696.460396080329,\n",
       "  'sl': {'y_pred': 287.88808237677245,\n",
       "   'y_prob': 287.7910901113736,\n",
       "   'level': 2,\n",
       "   'split': [0, 16.0],\n",
       "   'n_samples': 5924,\n",
       "   'gain': 2568.4745972426354,\n",
       "   'sl': {'y_pred': 247.79994511525797,\n",
       "    'y_prob': 247.66428963247395,\n",
       "    'level': 3,\n",
       "    'split': [0, 9.0],\n",
       "    'n_samples': 3644,\n",
       "    'gain': 1885.908175892786,\n",
       "    'sl': {'y_pred': 362.7692307692308,\n",
       "     'y_prob': 361.18380743982493,\n",
       "     'level': 4,\n",
       "     'split': [1, 1.0],\n",
       "     'n_samples': 455,\n",
       "     'gain': 29354.217896413506,\n",
       "     'sl': {'y_pred': 112.2551724137931,\n",
       "      'y_prob': 110.73469387755102,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 145,\n",
       "      'gain': 0},\n",
       "     'sr': {'y_pred': 479.9451612903226,\n",
       "      'y_prob': 476.87179487179486,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 310,\n",
       "      'gain': 0}},\n",
       "    'sr': {'y_pred': 231.3963624960803,\n",
       "     'y_prob': 231.25164525227203,\n",
       "     'level': 4,\n",
       "     'split': [1, 1.0],\n",
       "     'n_samples': 3189,\n",
       "     'gain': 4235.2791800001705,\n",
       "     'sl': {'y_pred': 326.64039408866995,\n",
       "      'y_prob': 325.99901671583086,\n",
       "      'level': 5,\n",
       "      'split': [0, 11.0],\n",
       "      'n_samples': 1015,\n",
       "      'gain': 4475.3298288238,\n",
       "      'sl': {'y_pred': 220.8655172413793,\n",
       "       'y_prob': 219.35616438356163,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 290,\n",
       "       'gain': 1843.9620570749084},\n",
       "      'sr': {'y_pred': 368.9503448275862,\n",
       "       'y_prob': 367.93672627235213,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 725,\n",
       "       'gain': 474.45852841854867}},\n",
       "     'sr': {'y_pred': 186.92870285188593,\n",
       "      'y_prob': 186.75735294117646,\n",
       "      'level': 5,\n",
       "      'split': [0, 10.0],\n",
       "      'n_samples': 2174,\n",
       "      'gain': 509.7813828072458,\n",
       "      'sl': {'y_pred': 242.29354838709676,\n",
       "       'y_prob': 240.74358974358975,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 310,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 177.72103004291844,\n",
       "       'y_prob': 177.53108252947482,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 1864,\n",
       "       'gain': 523.6110990589386}}}},\n",
       "   'sr': {'y_pred': 351.95877192982454,\n",
       "    'y_prob': 351.6507449605609,\n",
       "    'level': 3,\n",
       "    'split': [0, 19.0],\n",
       "    'n_samples': 2280,\n",
       "    'gain': 4273.148658850165,\n",
       "    'sl': {'y_pred': 405.3326023391813,\n",
       "     'y_prob': 404.7416058394161,\n",
       "     'level': 4,\n",
       "     'split': [0, 17.0],\n",
       "     'n_samples': 1368,\n",
       "     'gain': 3956.9225918338125,\n",
       "     'sl': {'y_pred': 316.37280701754383,\n",
       "      'y_prob': 314.99344978165936,\n",
       "      'level': 5,\n",
       "      'split': [1, 1.0],\n",
       "      'n_samples': 456,\n",
       "      'gain': 1225.820537806274,\n",
       "      'sl': {'y_pred': 367.64827586206894,\n",
       "       'y_prob': 362.6530612244898,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 145,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 292.4662379421222,\n",
       "       'y_prob': 290.6006389776358,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 311,\n",
       "       'gain': 0}},\n",
       "     'sr': {'y_pred': 449.8125,\n",
       "      'y_prob': 448.8293216630197,\n",
       "      'level': 5,\n",
       "      'split': [1, 1.0],\n",
       "      'n_samples': 912,\n",
       "      'gain': 8387.556471840697,\n",
       "      'sl': {'y_pred': 315.6862068965517,\n",
       "       'y_prob': 313.527397260274,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 290,\n",
       "       'gain': 549.336611177172},\n",
       "      'sr': {'y_pred': 512.347266881029,\n",
       "       'y_prob': 510.7067307692308,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 622,\n",
       "       'gain': 284.3181522110026}}},\n",
       "    'sr': {'y_pred': 271.8980263157895,\n",
       "     'y_prob': 271.30415754923416,\n",
       "     'level': 4,\n",
       "     'split': [0, 20.0],\n",
       "     'n_samples': 912,\n",
       "     'gain': 1881.866258127502,\n",
       "     'sl': {'y_pred': 315.2785087719298,\n",
       "      'y_prob': 313.90393013100436,\n",
       "      'level': 5,\n",
       "      'split': [1, 1.0],\n",
       "      'n_samples': 456,\n",
       "      'gain': 2480.0696734360026,\n",
       "      'sl': {'y_pred': 242.3448275862069,\n",
       "       'y_prob': 239.05442176870747,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 145,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 349.2829581993569,\n",
       "       'y_prob': 347.0543130990415,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 311,\n",
       "       'gain': 0}},\n",
       "     'sr': {'y_pred': 228.51754385964912,\n",
       "      'y_prob': 227.52183406113537,\n",
       "      'level': 5,\n",
       "      'split': [1, 1.0],\n",
       "      'n_samples': 456,\n",
       "      'gain': 932.0292202269484,\n",
       "      'sl': {'y_pred': 183.80689655172415,\n",
       "       'y_prob': 181.31292517006804,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 145,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 249.36334405144694,\n",
       "       'y_prob': 247.77316293929712,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 311,\n",
       "       'gain': 0}}}}},\n",
       "  'sr': {'y_pred': 132.15204678362574,\n",
       "   'y_prob': 131.95985401459853,\n",
       "   'level': 2,\n",
       "   'split': [0, 23.0],\n",
       "   'n_samples': 1368,\n",
       "   'gain': 909.224445128415,\n",
       "   'sl': {'y_pred': 153.47368421052633,\n",
       "    'y_prob': 153.13894967177242,\n",
       "    'level': 3,\n",
       "    'split': [0, 22.0],\n",
       "    'n_samples': 912,\n",
       "    'gain': 395.88781644352,\n",
       "    'sl': {'y_pred': 173.37061403508773,\n",
       "     'y_prob': 172.61572052401746,\n",
       "     'level': 4,\n",
       "     'split': [1, 1.0],\n",
       "     'n_samples': 456,\n",
       "     'gain': 282.8987633832885,\n",
       "     'sl': {'y_pred': 148.73793103448276,\n",
       "      'y_prob': 146.72108843537416,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 145,\n",
       "      'gain': 0},\n",
       "     'sr': {'y_pred': 184.85530546623795,\n",
       "      'y_prob': 183.67731629392972,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 311,\n",
       "      'gain': 0}},\n",
       "    'sr': {'y_pred': 133.5767543859649,\n",
       "     'y_prob': 132.99563318777294,\n",
       "     'level': 4,\n",
       "     'split': [1, 1.0],\n",
       "     'n_samples': 456,\n",
       "     'gain': 48.74575664988879,\n",
       "     'sl': {'y_pred': 123.35172413793103,\n",
       "      'y_prob': 121.68027210884354,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 145,\n",
       "      'gain': 0},\n",
       "     'sr': {'y_pred': 138.34405144694534,\n",
       "      'y_prob': 137.4632587859425,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 311,\n",
       "      'gain': 0}}},\n",
       "   'sr': {'y_pred': 89.50877192982456,\n",
       "    'y_prob': 89.12008733624454,\n",
       "    'level': 3,\n",
       "    'split': [1, 1.0],\n",
       "    'n_samples': 456,\n",
       "    'gain': 0.5622259304095678,\n",
       "    'sl': {'y_pred': 90.60689655172413,\n",
       "     'y_prob': 89.38095238095238,\n",
       "     'level': 4,\n",
       "     'split': -1,\n",
       "     'n_samples': 145,\n",
       "     'gain': 0},\n",
       "    'sr': {'y_pred': 88.9967845659164,\n",
       "     'y_prob': 88.43130990415335,\n",
       "     'level': 4,\n",
       "     'split': -1,\n",
       "     'n_samples': 311,\n",
       "     'gain': 0}}}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 4\n",
    "\n",
    "# Definición de la función que calcula el mse\n",
    "def mse(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.average(np.square(y-np.average(y)))\n",
    "\n",
    "# Definición de la función mse_gain para calular la ganancia de una variable predictora j dado el punto de corte k\n",
    "def mse_gain(X_col, y, split):\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    mse_y = mse(y)\n",
    "    mse_l = mse(y_l)\n",
    "    mse_r = mse(y_r)\n",
    "    \n",
    "    mse_gain_ = mse_y - (n_l / (n_l + n_r) * mse_l + n_r / (n_l + n_r) * mse_r)\n",
    "    \n",
    "    return mse_gain_\n",
    "\n",
    "# Definición de la función best_split para calcular cuál es la mejor variable y punto de corte para hacer la bifurcación del árbol\n",
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, mse_gain\n",
    "    \n",
    "    # Para todas las varibles \n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # Para cada partición\n",
    "        for split in splits:\n",
    "            gain = mse_gain(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split\n",
    "\n",
    "# Definición de la función tree_grow para hacer un crecimiento recursivo del árbol\n",
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # Si solo es una observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calcular la mejor división\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # Guardar el árbol y estimar la predicción\n",
    "    y_pred = y.mean()\n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Corrección Laplace \n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    # Revisar el criterio de parada \n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # Continuar creando la partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Siguiente iteración para cada partición\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "# Definición de la función tree_predict para hacer predicciones según las variables 'X' y el árbol 'tree'\n",
    "\n",
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Revisar si es el nodo final\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # Si el nodo izquierdo está vacio solo continua con el derecho \n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  #  Si el nodo derecho está vacio solo continua con el izquierdo\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted\n",
    "\n",
    "tree = tree_grow(X, y, level=0, min_gain=0.001, max_depth=6, num_pct=10)\n",
    "y_pred_manual_tree = tree_predict(X, tree, proba = False)\n",
    "\n",
    "print('El R_cuadrado del modelo basado en árboles es: ',r2_score(y, y_pred_manual_tree))\n",
    "print('El MSE del modelo de árboles es: ', mean_squared_error(y, y_pred_manual_tree))\n",
    "print('El RMSE del modelo de árboles es: ', np.sqrt(mean_squared_error(y, y_pred_manual_tree)))\n",
    "\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución\n",
    "\n",
    "1. **Procedimiento**\n",
    "\n",
    "El código anterior es una modificación del suministrado en el tutorial S1LAB1 indicando las siguientes precisiones:\n",
    "\n",
    "* La métrica del coeficiente de Gini se reemplazó por el MSE dado que el problema de representación es de Regresión, no clasificación.\n",
    "* La métrica del gini impurity se cambió por el mse_gain, el cual indica la variación del MSE entre las particiones.\n",
    "* En la función tree_grow, las predicciones `y_pred` se adaptaron para calcular el promedio de las observaciones en lugar de la regla lógica según el threshold de 0.5.\n",
    "* Se evaluó el desempeño entrenando y validando con la totalidad de los datos, esto dado que en el enunciado del punto anterior indican que se debe usar todo el conjunto para la validación, y posteriormente se ha de comparar este resultado contra la ejecuciñon de una librería (`scikit-learn`).\n",
    "* Las métricas empleadas para evaluar son el $R^2$ , el MSE y RMSE.\n",
    "\n",
    "2. **Análisis**\n",
    "\n",
    "El árbol se evaluó con un criterio de parada basado en una profundidad de 6. Se encuentra un $R^2$ de 0.647 lo que implica que el modelo es capaz de representar de mejor manera la varianza inherente comparativametne con la regresión lineal simple. Se encuentra también una disminución en el valor del MSE general del modelo, lo que implica un aumento en el poder predictivo del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Árbol de decisión con librería\n",
    "En la celda 5 entrene un árbol de decisiones con la **librería sklearn**, usando las variables predictoras \"hour\" y \"workingday\" y calibre los parámetros que considere conveniente para obtener un mejor desempeño. Comente el desempeño del modelo con alguna métrica de desempeño de modelos de clasificación y compare desempeño con el modelo del punto 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Parámetro de max_depth\n",
      "   max_depth     Neg - MSE\n",
      "9         10 -13143.121883\n",
      "\n",
      "El R_cuadrado del modelo basado en árboles es:  0.6547025809438785\n",
      "El RMSE del modelo de árboles es:  106.43923864758072\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_cuad</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Reg</th>\n",
       "      <td>0.160591</td>\n",
       "      <td>165.955582</td>\n",
       "      <td>27541.255252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tree</th>\n",
       "      <td>0.654703</td>\n",
       "      <td>106.439239</td>\n",
       "      <td>11329.311524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              R_cuad        RMSE           MSE\n",
       "Linear Reg  0.160591  165.955582  27541.255252\n",
       "Tree        0.654703  106.439239  11329.311524"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 5\n",
    "\n",
    "# Se establece un rango de 1 a 40 en saltos de una unidad para explorar el desempeño predictivo\n",
    "max_depth_range = range(1, 40)\n",
    "\n",
    "# Lista para guardar los valores del MSE para cada valor de máxima profundidad (max_depth)\n",
    "mse_scores = []\n",
    "\n",
    "# Ciclo para obtener el desempeño del modelo de acuerdo con la máxima profundidad usando K-fold cross validation con 10 pliegues\n",
    "for depth in max_depth_range:\n",
    "    # Definición del árbol de decisión usando DecisionTreeClassifier de la libreria sklearn\n",
    "    reg = DecisionTreeRegressor(max_depth=depth, random_state=1)\n",
    "    mse_scores.append(cross_val_score(reg, X, y, cv=10, scoring='neg_mean_squared_error').mean())\n",
    "\n",
    "# Gráfica max_depth versus MSE (error del modelo)\n",
    "plt.plot(max_depth_range, mse_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.title('Hyperparameter Calibration')\n",
    "plt.ylabel('Neg - MSE')\n",
    "\n",
    "# Se obtiene el parámetro de maxima profundidad adecuado para tener el menor MSE posible\n",
    "parameters = pd.DataFrame({'max_depth':max_depth_range,'Neg - MSE' : mse_scores}).sort_values(by = ['Neg - MSE','max_depth'], ascending = [False,True]).head(1)\n",
    "\n",
    "print('Mejor Parámetro de max_depth')\n",
    "print(parameters)\n",
    "print()\n",
    "# Entrenar el árbol de decisión haciendo uso del parámetro de calibración\n",
    "reg = DecisionTreeRegressor(max_depth=parameters.iloc[0,0], random_state=1)\n",
    "reg.fit(X, y)\n",
    "\n",
    "# Generar las predicciones para todo el conjunto de datos\n",
    "y_pred_tree_lib = reg.predict(X)\n",
    "\n",
    "# Evaluación del desempeño predictivo del modelo usando Scikit-learn\n",
    "print('El R_cuadrado del modelo basado en árboles es: ',r2_score(y, y_pred_tree_lib))\n",
    "print('El RMSE del modelo de árboles es: ', np.sqrt(mean_squared_error(y, y_pred_tree_lib)))\n",
    "\n",
    "model_comparison = pd.DataFrame({'R_cuad':[r2_score(y, y_pred_lr),r2_score(y, y_pred_tree_lib)],\n",
    "              'RMSE':[np.sqrt(mean_squared_error(y, y_pred_lr)),np.sqrt(mean_squared_error(y, y_pred_tree_lib))],\n",
    "              'MSE':[mean_squared_error(y, y_pred_lr),mean_squared_error(y, y_pred_tree_lib)]}, index = ['Linear Reg','Tree'])\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>workingday</td>\n",
       "      <td>0.18495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.81505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "1  workingday     0.18495\n",
       "0        hour     0.81505"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'feature':X.columns, 'importance':reg.feature_importances_}).sort_values('importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución\n",
    "\n",
    "1. **Procedimiento**\n",
    "\n",
    "Se realizó una calibración manual del hiperparámetro max_depth en un espacio de 0 a 39, identificando mediante validación cruzada aquel que da el mejor MSE. Usando esta calibración se entrena el modelo de árbol de regresión y se compara contra el resultado de la regresión lineal por mínimos cuadrados construida en el punto 3. También se analiza la importancia de las variables predictoras empleadas en el modelo.\n",
    "\n",
    "2. **Análisis**\n",
    "\n",
    "Con una profundidad de 10 se obtiene un MSE de 13143.121, siendo el mejor de los 3 modelos creados hasta el momento (lineal, manual y optimizado por librería). Comparativamente también se evidencia que el modelo más flexible (Árbol de Regresión) tiene un $R^2$ de 0.65, que supera la capacidad de representar la varianza del fenómeno de alquiler de bicicletas.\n",
    "\n",
    "En términos de importancia de variables,se encuentra consistencia entre los hallazgos del modelo lineal y el basado en árboles, la variable `hour` es más relevante que `workingday` para la predicción acertada de `total`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte B - Métodos de ensamblajes\n",
    "En esta parte del taller se usará el conjunto de datos de Popularidad de Noticias Online. El objetivo es predecir si la notica es popular o no, la populridad esta dada por la cantidad de reacciones en redes sociales. Para más detalles puede visitar el sigueinte enlace: [datos](https://archive.ics.uci.edu/ml/datasets/online+news+popularity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos popularidad de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "0                  0.844262        5.0             1.0       1.0  ...   \n",
       "1                  0.815789        9.0             4.0       1.0  ...   \n",
       "2                  0.775701        4.0             3.0       1.0  ...   \n",
       "3                  0.677350       10.0             3.0       1.0  ...   \n",
       "4                  0.830357        3.0             2.0       1.0  ...   \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/mashable.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición variable de interes y variables predictoras\n",
    "X = df.drop(['url', 'Popular'], axis=1)\n",
    "y = df['Popular']\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de la muestra en set de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - Árbol de decisión y regresión logística\n",
    "En la celda 6 construya un árbol de decisión y una regresión logística. Para el árbol calibre al menos un parámetro y evalúe el desempeño de cada modelo usando las métricas de Accuracy y F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor del F1-Score de la Reg. Logística es:  0.6106254203093476\n",
      "El valor del Accuracy de la Reg. Logística es:  0.614\n",
      "El valor del F1-Score del arbol de clasificación es:  0.6448598130841121\n",
      "El valor del Accuracy del arbol de clasificación es:  0.6453333333333333\n"
     ]
    }
   ],
   "source": [
    "# Celda 6\n",
    "\n",
    "# Regresión Logística\n",
    "# Construir y entrenar el modelo de regresión logística\n",
    "log_reg = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "# Predecir en la muestra de validación con la regresión logística\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print('El valor del F1-Score de la Reg. Logística es: ', f1_score(y_test, y_pred_log_reg))\n",
    "print('El valor del Accuracy de la Reg. Logística es: ', accuracy_score(y_test, y_pred_log_reg))\n",
    "\n",
    "# Árbol de decisión\n",
    "# Construir árbol de decisión\n",
    "params = {'criterion':['gini'], 'max_depth': [i for i in range(1, 40)]}\n",
    "clf_tree = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid = params, cv = 10)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "y_pred_clf_tree = clf_tree.predict(X_test)\n",
    "print('El valor del F1-Score del arbol de clasificación es: ', f1_score(y_test, y_pred_clf_tree))\n",
    "print('El valor del Accuracy del arbol de clasificación es: ', accuracy_score(y_test, y_pred_clf_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solucion\n",
    "\n",
    "1. **Procedimiento**\n",
    "\n",
    "Se crea un modelo de regresión logística, usando la librería de scikit-learn, la cual por defecto usa una regularización RIDGE, y se entrena este modelo con la muestra de entrenamiento. Después se valida con la muestra de test y se calculan las métricas solicitadas.\n",
    "Se hace lo propio con el modelo de árboles de clasificación, usando una calibración de hiperparámetros mediante una búsqueda con GridSearch y validación cruzada de k-fold = 10 sobre la muestra de entrenamiento. Esto permitirá entrenar el mejor árbol empleando el max_depth inspeccionado. Se escoge esta alternativa para no tener que hacer la inspección manual como en el punto 5.\n",
    "Luego se comparan las métricas de los modelos.\n",
    "\n",
    "2. **Análisis**\n",
    "\n",
    "La regresión logística aporta un Accuracy de 0.614 mientras que el árbol calibrado ofrece uno de 0.645, siendo el árbol mejor también en el F1-Score. Se puede concluir que el árbol de decisión tiene un mejor poder predictivo para la muestra de validación disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Votación Mayoritaria\n",
    "En la celda 7 elabore un esamble con la metodología de **Votación mayoritaria** compuesto por 300 muestras bagged para cada uno de los siguientes escenarios:\n",
    "\n",
    "-100 árboles de decisión donde max_depth = None\\\n",
    "-100 árboles de decisión donde max_depth = 2\\\n",
    "-100 regresiones logísticas\n",
    "\n",
    "Evalúe los modelos utilizando las métricas de Accuracy y F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor del F1-Score del Escenario 1 es:  0.6567567567567568\n",
      "El valor del Accuracy del Escenario 1 es:  0.6613333333333333\n",
      "El valor del F1-Score del Escenario 2 es:  0.631578947368421\n",
      "El valor del Accuracy del Escenario 2 es:  0.6453333333333333\n",
      "El valor del F1-Score del Escenario 3 es:  0.6128813559322034\n",
      "El valor del Accuracy del Escenario 3 es:  0.6193333333333333\n"
     ]
    }
   ],
   "source": [
    "# Celda 7\n",
    "\n",
    "# Escenario 1\n",
    "\n",
    "esc_1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth = None), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True, max_samples = 300)\n",
    "esc_1.fit(X_train, y_train)\n",
    "y_pred_esc_1 = esc_1.predict(X_test)\n",
    "print('El valor del F1-Score del Escenario 1 es: ', f1_score(y_test, y_pred_esc_1))\n",
    "print('El valor del Accuracy del Escenario 1 es: ', accuracy_score(y_test, y_pred_esc_1))\n",
    "# Escenario 2\n",
    "\n",
    "esc_2 = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth = 2), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True, max_samples = 300)\n",
    "esc_2.fit(X_train, y_train)\n",
    "y_pred_esc_2 = esc_2.predict(X_test)\n",
    "print('El valor del F1-Score del Escenario 2 es: ', f1_score(y_test, y_pred_esc_2))\n",
    "print('El valor del Accuracy del Escenario 2 es: ', accuracy_score(y_test, y_pred_esc_2))\n",
    "# Escenario 3\n",
    "\n",
    "esc_3 = BaggingClassifier(base_estimator=LogisticRegression(random_state = 1), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True, max_samples = 300)\n",
    "esc_3.fit(X_train, y_train)\n",
    "y_pred_esc_3 = esc_3.predict(X_test)\n",
    "print('El valor del F1-Score del Escenario 3 es: ', f1_score(y_test, y_pred_esc_3))\n",
    "print('El valor del Accuracy del Escenario 3 es: ', accuracy_score(y_test, y_pred_esc_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución\n",
    "\n",
    "1. **Procedimiento**\n",
    "\n",
    "Se realiza un ensamble mediante la libreria de scikit-learn para cada uno de los escenarios y se evaluan sus desempeños.\n",
    "\n",
    "2. **Conclusiones**\n",
    "\n",
    "El modelo con el mejor desempeño es el ensamblado con 300 árboles de clasificación y 300 muestras bootstrap y una profundidad de 2, esto basado en que tanto su F1-Score y su Accuracy son las más altas. Por su parte el modelo sin criterio de parada por profundidad el segundo más poderoso, mientras que la regreisón logística es el modelo que tiene el poder predictivo más bajo. Sin, embargo es de anotar que ninguno de los 3 modelos tiene una dominancia clara sobre la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Votación Ponderada\n",
    "En la celda 8 elabore un ensamble con la metodología de **Votación ponderada** compuesto por 300 muestras bagged para los mismos tres escenarios del punto 7. Evalúe los modelos utilizando las métricas de Accuracy y F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votacion Ponderada\n",
      "Escenario 1\n",
      "El valor del F1-Score del Escenario 1 Ponderado es:  0.6631087391594397\n",
      "El valor del Accuracy del Escenario 1 Ponderado es:  0.6633333333333333\n",
      "Escenario 2\n",
      "El valor del F1-Score del Escenario 2 Ponderado es:  0.6324549237170597\n",
      "El valor del Accuracy del Escenario 2 Ponderado es:  0.6466666666666666\n",
      "Escenario 3\n",
      "El valor del F1-Score del Escenario 3 Ponderado es:  0.6167341430499326\n",
      "El valor del Accuracy del Escenario 3 Ponderado es:  0.6213333333333333\n"
     ]
    }
   ],
   "source": [
    "# Celda 8\n",
    "print('Votacion Ponderada')\n",
    "#Escenario 1\n",
    "clf_esc_1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth = None), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True, max_samples = 300)\n",
    "\n",
    "# Predicción y desempeño al hacer votación mayoritaria\n",
    "clf_esc_1.fit(X_train, y_train)\n",
    "y_pred_pond_esc_1 = clf_esc_1.predict(X_test)\n",
    "\n",
    "errors_esc_1 = np.zeros(clf_esc_1.n_estimators)\n",
    "y_pred_all_esc_1 = np.zeros((X_test.shape[0], clf_esc_1.n_estimators))\n",
    "\n",
    "for i in range(clf_esc_1.n_estimators):\n",
    "    oob_sample_esc_1 = ~clf_esc_1.estimators_samples_[i]\n",
    "    y_pred_pond_1 = clf_esc_1.estimators_[i].predict(X_train.values[oob_sample_esc_1])\n",
    "    errors_esc_1[i] = accuracy_score(y_pred_pond_1, y_train.values[oob_sample_esc_1])\n",
    "    y_pred_all_esc_1[:, i] = clf_esc_1.estimators_[i].predict(X_test)\n",
    "    \n",
    "alpha_esc_1 = (1 - errors_esc_1) / (1 - errors_esc_1).sum()\n",
    "y_pred_pond_esc_1 = (np.sum(y_pred_all_esc_1 * alpha_esc_1, axis=1) >= 0.5).astype(np.int)\n",
    "print('Escenario 1')\n",
    "print('El valor del F1-Score del Escenario 1 Ponderado es: ', f1_score(y_test, y_pred_pond_esc_1))\n",
    "print('El valor del Accuracy del Escenario 1 Ponderado es: ', accuracy_score(y_test, y_pred_pond_esc_1))\n",
    "\n",
    "#Escenario 2\n",
    "clf_esc_2 = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth = 2), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True, max_samples = 300)\n",
    "\n",
    "# Predicción y desempeño al hacer votación mayoritaria\n",
    "clf_esc_2.fit(X_train, y_train)\n",
    "y_pred_pond_esc_2 = clf_esc_2.predict(X_test)\n",
    "\n",
    "errors_esc_2 = np.zeros(clf_esc_2.n_estimators)\n",
    "y_pred_all_esc_2 = np.zeros((X_test.shape[0], clf_esc_2.n_estimators))\n",
    "\n",
    "for i in range(clf_esc_2.n_estimators):\n",
    "    oob_sample_esc_2 = ~clf_esc_2.estimators_samples_[i]\n",
    "    y_pred_pond_2 = clf_esc_2.estimators_[i].predict(X_train.values[oob_sample_esc_2])\n",
    "    errors_esc_2[i] = accuracy_score(y_pred_pond_2, y_train.values[oob_sample_esc_2])\n",
    "    y_pred_all_esc_2[:, i] = clf_esc_2.estimators_[i].predict(X_test)\n",
    "    \n",
    "alpha_esc_2 = (1 - errors_esc_2) / (1 - errors_esc_2).sum()\n",
    "y_pred_pond_esc_2 = (np.sum(y_pred_all_esc_2 * alpha_esc_2, axis=1) >= 0.5).astype(np.int)\n",
    "print('Escenario 2')\n",
    "print('El valor del F1-Score del Escenario 2 Ponderado es: ', f1_score(y_test, y_pred_pond_esc_2))\n",
    "print('El valor del Accuracy del Escenario 2 Ponderado es: ', accuracy_score(y_test, y_pred_pond_esc_2))\n",
    "\n",
    "#Escenario 3\n",
    "clf_esc_3 = BaggingClassifier(base_estimator=LogisticRegression(random_state = 1), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True, max_samples = 300)\n",
    "\n",
    "# Predicción y desempeño al hacer votación mayoritaria\n",
    "clf_esc_3.fit(X_train, y_train)\n",
    "y_pred_pond_esc_3 = clf_esc_3.predict(X_test)\n",
    "\n",
    "errors_esc_3 = np.zeros(clf_esc_3.n_estimators)\n",
    "y_pred_all_esc_3 = np.zeros((X_test.shape[0], clf_esc_3.n_estimators))\n",
    "\n",
    "for i in range(clf_esc_3.n_estimators):\n",
    "    oob_sample_esc_3 = ~clf_esc_3.estimators_samples_[i]\n",
    "    y_pred_pond_3 = clf_esc_3.estimators_[i].predict(X_train.values[oob_sample_esc_3])\n",
    "    errors_esc_3[i] = accuracy_score(y_pred_pond_3, y_train.values[oob_sample_esc_3])\n",
    "    y_pred_all_esc_3[:, i] = clf_esc_3.estimators_[i].predict(X_test)\n",
    "    \n",
    "alpha_esc_3 = (1 - errors_esc_3) / (1 - errors_esc_3).sum()\n",
    "y_pred_pond_esc_3 = (np.sum(y_pred_all_esc_3 * alpha_esc_3, axis=1) >= 0.5).astype(np.int)\n",
    "print('Escenario 3')\n",
    "print('El valor del F1-Score del Escenario 3 Ponderado es: ', f1_score(y_test, y_pred_pond_esc_3))\n",
    "print('El valor del Accuracy del Escenario 3 Ponderado es: ', accuracy_score(y_test, y_pred_pond_esc_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución\n",
    "\n",
    "1. **Procedimiento**\n",
    "\n",
    "Se realiza un ensamble ponderado mediante la libreria de scikit-learn para cada uno de los escenarios y se evaluan sus desempeños.\n",
    "\n",
    "2. **Conclusiones**\n",
    "\n",
    "El escenario 1 es aquel que oferta un mejor resultado predictivo de los 3 distintos modelos evaluados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 9 - Comparación y análisis de resultados\n",
    "En la celda 9 comente sobre los resultados obtenidos con las metodologías usadas en los puntos 7 y 8, compare los resultados y enuncie posibles ventajas o desventajas de cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Score Mayoritario</th>\n",
       "      <th>Accuracy Mayoritario</th>\n",
       "      <th>F1-Score Ponderado</th>\n",
       "      <th>Accuracy Ponderado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Escenario 1</th>\n",
       "      <td>0.656757</td>\n",
       "      <td>0.661333</td>\n",
       "      <td>0.663109</td>\n",
       "      <td>0.663333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Escenario 2</th>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.645333</td>\n",
       "      <td>0.632455</td>\n",
       "      <td>0.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Escenario 3</th>\n",
       "      <td>0.612881</td>\n",
       "      <td>0.619333</td>\n",
       "      <td>0.616734</td>\n",
       "      <td>0.621333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             F1-Score Mayoritario  Accuracy Mayoritario  F1-Score Ponderado  \\\n",
       "Escenario 1              0.656757              0.661333            0.663109   \n",
       "Escenario 2              0.631579              0.645333            0.632455   \n",
       "Escenario 3              0.612881              0.619333            0.616734   \n",
       "\n",
       "             Accuracy Ponderado  \n",
       "Escenario 1            0.663333  \n",
       "Escenario 2            0.646667  \n",
       "Escenario 3            0.621333  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Celda 9\n",
    "\n",
    "pd.DataFrame({ \"F1-Score Mayoritario\": [f1_score(y_test, y_pred_esc_1),f1_score(y_test, y_pred_esc_2),f1_score(y_test, y_pred_esc_3)],\n",
    "               \"Accuracy Mayoritario\": [accuracy_score(y_test, y_pred_esc_1),accuracy_score(y_test, y_pred_esc_2),accuracy_score(y_test, y_pred_esc_3)],\n",
    "               \"F1-Score Ponderado\": [f1_score(y_test, y_pred_pond_esc_1),f1_score(y_test, y_pred_pond_esc_2),f1_score(y_test, y_pred_pond_esc_3)],\n",
    "               \"Accuracy Ponderado\": [accuracy_score(y_test, y_pred_pond_esc_1),accuracy_score(y_test, y_pred_pond_esc_2),accuracy_score(y_test, y_pred_pond_esc_3)]\n",
    "             }, index = ['Escenario 1','Escenario 2','Escenario 3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución\n",
    "\n",
    "**Comentarios y Comparación de los modelos**\n",
    "\n",
    "El método ponderado es ligeramente más acertado al momento de realizar las predicciones con el conjunto de datos en comparación a su contraprarte mayoritaria, para cualquiera de los escenarios analizados. En en general aquel que no tiene el criterio de parada sobre profundidad tiende a ser aquel que mejor desempeño tiene en las métricas revisadas.\n",
    "\n",
    "**Ventajas /  Desventajas**\n",
    "\n",
    "Como ventaja se puede indicar que los modelos basados en ensamble pueden ayudar disminuir la varianza de los árboles. Sin embargo la profundidad de revisión puede aumentar la complejidad del modelo y así mismo, los modelos que usan ponderaciones dependen bastante de los datos de origen para establecer los pesos de sus decisiones haciendolos dificiles de replicar con exactitud en otros entornos. El uso de modelos simples para realizar las clasificaciones como las regresiones logísticas, son bastante suceptibles a outliers, variaciones en el origen de datos y el balanceo de las clases, en contraprestación a los árboles que son relativamente más robustos a estas situaciones, por lo tanto es común encontrar que estos algoritmos más flexibles (árboles) tienen un mejor desempeño predictivo; sin embargo también suelen ser afectados por el overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
